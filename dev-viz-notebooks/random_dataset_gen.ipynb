{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../src')))\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from pubmetric.network import create_citation_network \n",
    "from pubmetric.workflow import *\n",
    "from pubmetric.metrics import *\n",
    "from pubmetric.pckg_dev import generate_random_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-06 13:48:17 - Graph loaded from ../out_20240801231111\n"
     ]
    }
   ],
   "source": [
    "path_to_data = '../out_20240801231111' \n",
    "loaded_graph = asyncio.run(create_citation_network(inpath=path_to_data, load_graph=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing that loading one Workflomics produced CWL workflow works\n",
    "These have urls to containers, which is needed for the cwl_utils.parser function load_document_by_uri to work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwl_file_path = \"../workflows/workflomics/candidate_workflow_23.cwl\" # loading one of the APE generated workflows \n",
    "workflow = parse_cwl_workflows(loaded_graph, cwl_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a random workflow of the same structure. Each radnom tool is picked from a pool of tools with a siilar degree (using a range of +-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_workflow = generate_random_workflow(graph=loaded_graph, workflow=workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that they look the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"edges\": [\n",
      "        [\n",
      "            \"XTandem_01\",\n",
      "            \"ProteinProphet_02\"\n",
      "        ],\n",
      "        [\n",
      "            \"ProteinProphet_02\",\n",
      "            \"StPeter_04\"\n",
      "        ],\n",
      "        [\n",
      "            \"XTandem_03\",\n",
      "            \"StPeter_04\"\n",
      "        ]\n",
      "    ],\n",
      "    \"steps\": {\n",
      "        \"ProteinProphet_02\": \"14632076\",\n",
      "        \"StPeter_04\": \"29400476\",\n",
      "        \"XTandem_01\": \"14976030\",\n",
      "        \"XTandem_03\": \"14976030\"\n",
      "    },\n",
      "    \"pmid_edges\": [\n",
      "        [\n",
      "            \"14976030\",\n",
      "            \"14632076\"\n",
      "        ],\n",
      "        [\n",
      "            \"14632076\",\n",
      "            \"29400476\"\n",
      "        ],\n",
      "        [\n",
      "            \"14976030\",\n",
      "            \"29400476\"\n",
      "        ]\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"edges\": [\n",
      "        [\n",
      "            \"PeptideProphet_01\",\n",
      "            \"ProteinProphet_02\"\n",
      "        ],\n",
      "        [\n",
      "            \"ProteinProphet_02\",\n",
      "            \"ProteinInfer_04\"\n",
      "        ],\n",
      "        [\n",
      "            \"PeptideProphet_03\",\n",
      "            \"ProteinInfer_04\"\n",
      "        ]\n",
      "    ],\n",
      "    \"steps\": {\n",
      "        \"PeptideProphet_01\": \"12403597\",\n",
      "        \"ProteinProphet_02\": \"14632076\",\n",
      "        \"ProteinInfer_04\": \"24407311\",\n",
      "        \"PeptideProphet_03\": \"12403597\"\n",
      "    },\n",
      "    \"pmid_edges\": [\n",
      "        [\n",
      "            \"12403597\",\n",
      "            \"14632076\"\n",
      "        ],\n",
      "        [\n",
      "            \"14632076\",\n",
      "            \"24407311\"\n",
      "        ],\n",
      "        [\n",
      "            \"12403597\",\n",
      "            \"24407311\"\n",
      "        ]\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(workflow, indent=4)) # \n",
    "print(json.dumps(random_workflow, indent=4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test that loading one APE generated workflow (without uri) works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"edges\": [\n",
      "        [\n",
      "            \"CrosstalkDB_01\",\n",
      "            \"CrosstalkDB_02\"\n",
      "        ],\n",
      "        [\n",
      "            \"CrosstalkDB_02\",\n",
      "            \"MSiReader_03\"\n",
      "        ],\n",
      "        [\n",
      "            \"MSiReader_03\",\n",
      "            \"ComPIL_04\"\n",
      "        ],\n",
      "        [\n",
      "            \"ComPIL_04\",\n",
      "            \"isobar_05\"\n",
      "        ]\n",
      "    ],\n",
      "    \"steps\": {\n",
      "        \"CrosstalkDB_01\": \"24741113\",\n",
      "        \"CrosstalkDB_02\": \"24741113\",\n",
      "        \"MSiReader_03\": \"23536269\",\n",
      "        \"ComPIL_04\": \"30525664\",\n",
      "        \"isobar_05\": \"21526793\"\n",
      "    },\n",
      "    \"pmid_edges\": [\n",
      "        [\n",
      "            \"24741113\",\n",
      "            \"24741113\"\n",
      "        ],\n",
      "        [\n",
      "            \"24741113\",\n",
      "            \"23536269\"\n",
      "        ],\n",
      "        [\n",
      "            \"23536269\",\n",
      "            \"30525664\"\n",
      "        ],\n",
      "        [\n",
      "            \"30525664\",\n",
      "            \"21526793\"\n",
      "        ]\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cwl_file_path = \"../workflows/APE/candidate_workflow_23.cwl\" # loading one of the APE generated workflows \n",
    "undoc_workflow = parse_undocumented_workflows(loaded_graph, cwl_file_path)\n",
    "print(json.dumps(undoc_workflow, indent=4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating and saving a random dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random dataset will be based on 1000 APE generated workflows in the proteomics domain. Out of these 1000 workflows, only the ones with at most one undefined pmid in the graph will be used. For each of these a randomly generated conterpart will be generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition\n",
      "Repetition\n",
      "Repetition\n",
      "Repetition\n"
     ]
    }
   ],
   "source": [
    "# Because of a problem with the naming in APE the 8 and 9s are skipped, thus the id of the 1000th workflow is 1750. \n",
    "random_dataset = []\n",
    "ape_tools = []\n",
    "random_tools = []\n",
    "\n",
    "ape_edges = []\n",
    "random_edges = []\n",
    "\n",
    "ape_worfklows = []\n",
    "\n",
    "for i in range(1,1751):\n",
    "    if '8' in str(i) or '9' in str(i):\n",
    "        continue\n",
    "    cwl_file_path = f\"../workflows/APE/candidate_workflow_{i}.cwl\" #\n",
    "    workflow = parse_undocumented_workflows(loaded_graph, cwl_file_path)\n",
    "\n",
    "    if workflow['edges'] in ape_worfklows:\n",
    "        print('Repetition')\n",
    "        continue\n",
    "    else:\n",
    "        ape_worfklows.append(workflow['edges'])\n",
    "\n",
    "    workflow_pmids = workflow['steps'].values()\n",
    "    if len([pmid for pmid in workflow_pmids if not pmid]) <=1:\n",
    "        random_workflow = generate_random_workflow(graph=loaded_graph, workflow=workflow)\n",
    "        random_workflow_pmids = random_workflow['steps'].values()\n",
    "\n",
    "        ape_tools += workflow_pmids\n",
    "        random_tools += random_workflow_pmids\n",
    "        ape_edges += [(edge[0], edge[1]) for edge in workflow['edges']]\n",
    "        random_edges += [(edge[0], edge[1]) for edge in random_workflow['edges']]\n",
    "\n",
    "        \n",
    "\n",
    "        # To save the dataset\n",
    "        random_dataset.append( {\n",
    "            'APE_workflow': workflow,\n",
    "            'random_workflow': random_workflow\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ape_tools = np.unique([t for t in ape_tools if t])\n",
    "unique_random_tools = np.unique([t for t in random_tools if t])\n",
    "\n",
    "unique_ape_edges = np.unique([t for t in ape_edges if t])\n",
    "unique_random_edges = np.unique([t for t in random_edges if t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669\n"
     ]
    }
   ],
   "source": [
    "print(len(random_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/random_dataset.json\", 'w') as f:\n",
    "    json.dump(random_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats on the random data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "96\n",
      "146\n",
      "286\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_random_tools))\n",
    "print(len(unique_ape_tools))\n",
    "print(len(unique_random_edges))\n",
    "print(len(unique_ape_edges))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WFQC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
